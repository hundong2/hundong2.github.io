---
title: "C++ - NVIDIA CUDA 그래프 (CUDA Graphs)"
date: 2025-12-04 21:03:48 +0900
categories: c++
tags: [c++, 최신기술, 추천, C++, NVIDIA, CUDA, 그래프, (CUDA, Graphs)]
---

## 오늘의 C++ 최신 기술 트렌드: **NVIDIA CUDA 그래프 (CUDA Graphs)**

**1. 간단한 설명:**

CUDA 그래프는 일련의 CUDA 연산을 단일 단위로 캡슐화하여 GPU에서 실행할 수 있도록 하는 기술입니다. 기존 CUDA 프로그래밍 방식에서는 CPU가 각 커널 호출을 시작하고 관리해야 했지만, CUDA 그래프를 사용하면 CPU의 개입을 최소화하고 GPU에서 직접 그래프를 실행할 수 있습니다. 이는 커널 실행 오버헤드를 줄이고, latency를 낮추며, 전체 애플리케이션 성능을 향상시키는 데 도움이 됩니다. 특히, 딥러닝 추론, 물리 시뮬레이션, 고성능 컴퓨팅과 같이 반복적인 커널 실행 패턴을 가진 애플리케이션에서 큰 효과를 볼 수 있습니다. 또한, CUDA 그래프는 동적 재기록(dynamic re-recording) 및 그래프 편집 기능을 제공하여 유연성을 높여줍니다. C++를 사용해 CUDA 그래프를 정의하고 관리하는 것이 일반적입니다.

**2. 참고할 만한 공식 사이트나 블로그 링크:**

*   **NVIDIA CUDA Documentation:** [https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-graphs](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-graphs)
*   **NVIDIA Developer Blog:** [https://developer.nvidia.com/blog/cuda-graphs/](https://developer.nvidia.com/blog/cuda-graphs/)

**3. 간단한 코드 예시 (C++):**

```c++
#include <iostream>
#include <cuda_runtime.h>

// 간단한 벡터 덧셈 커널
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    c[idx] = a[idx] + b[idx];
  }
}

int main() {
  int n = 1024;
  float *h_a, *h_b, *h_c; // 호스트 메모리
  float *d_a, *d_b, *d_c; // 디바이스 메모리

  // 호스트 메모리 할당
  h_a = new float[n];
  h_b = new float[n];
  h_c = new float[n];

  // 데이터 초기화
  for (int i = 0; i < n; ++i) {
    h_a[i] = i;
    h_b[i] = i * 2;
  }

  // 디바이스 메모리 할당
  cudaMalloc(&d_a, n * sizeof(float));
  cudaMalloc(&d_b, n * sizeof(float));
  cudaMalloc(&d_c, n * sizeof(float));

  // 데이터 호스트 -> 디바이스 복사
  cudaMemcpy(d_a, h_a, n * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, h_b, n * sizeof(float), cudaMemcpyHostToDevice);

  // CUDA 그래프 생성
  cudaGraph_t graph;
  cudaGraphCreate(&graph, 0);

  cudaGraphNodeParams params = {};

  cudaStreamCaptureMode captureMode = cudaStreamCaptureModeGlobal;

  cudaStream_t stream;
  cudaStreamCreate(&stream);

  cudaStreamBeginCapture(stream, captureMode);

  // 커널 실행 구성
  dim3 blockDim(256);
  dim3 gridDim((n + blockDim.x - 1) / blockDim.x);

  vectorAdd<<<gridDim, blockDim, 0, stream>>>(d_a, d_b, d_c, n);
  cudaStreamEndCapture(stream, &graph);

  cudaGraphExec_t instance;
  cudaGraphInstantiate(&instance, graph, NULL, NULL, 0);

  // 그래프 실행
  cudaGraphLaunch(instance, stream);
  cudaStreamSynchronize(stream);

  // 결과 디바이스 -> 호스트 복사
  cudaMemcpy(h_c, d_c, n * sizeof(float), cudaMemcpyDeviceToHost);

  // 결과 확인 (첫 10개 요소만)
  std::cout << "Result: ";
  for (int i = 0; i < 10; ++i) {
    std::cout << h_c[i] << " ";
  }
  std::cout << std::endl;

  // 메모리 해제
  delete[] h_a;
  delete[] h_b;
  delete[] h_c;
  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);
  cudaGraphExecDestroy(instance);
  cudaGraphDestroy(graph);
  cudaStreamDestroy(stream);

  return 0;
}
```

**4. 코드 실행 결과 예시:**

```
Result: 0 3 6 9 12 15 18 21 24 27
```
