---
title: "AI - World Models"
date: 2025-07-29 21:03:14 +0900
categories: ai
tags: [ai, 최신기술, 추천, AI, World, Models]
---

## 오늘의 AI 최신 기술 트렌드: **World Models**

**1. 간단한 설명:**

World Models는 에이전트가 환경의 간결한 내부 모델을 학습하여 계획, 의사 결정, 일반화를 수행할 수 있도록 하는 AI 아키텍처입니다. 기본적인 아이디어는 에이전트가 실제 세계와 상호 작용하는 대신, 학습된 "세계 모델" 내에서 시뮬레이션된 환경에서 전략을 학습한다는 것입니다. 이 모델은 과거 경험을 바탕으로 미래를 예측하고, 에이전트가 예상되는 결과를 기반으로 계획을 세울 수 있도록 합니다. 핵심 구성 요소는 다음과 같습니다:

*   **Variational Autoencoder (VAE):** 고차원 입력(예: 이미지)을 압축된 잠재 공간 표현으로 인코딩합니다.
*   **Recurrent Neural Network (RNN):** 잠재 공간 표현을 사용하여 미래 상태를 예측합니다.
*   **Controller:** 예측된 미래 상태를 기반으로 에이전트의 행동을 결정합니다.

World Models의 장점은 다음과 같습니다:

*   **샘플 효율성:** 실제 환경과의 상호 작용을 최소화하여 학습 속도를 향상시킵니다.
*   **일반화 능력:** 다양한 환경에서 작동할 수 있는 강력한 정책을 학습합니다.
*   **계획 능력:** 미래를 예측하여 장기적인 목표를 달성하기 위한 전략을 세웁니다.
*   **해석 가능성:** 내부 모델을 분석하여 에이전트의 의사 결정 과정을 이해할 수 있습니다.

**2. 참고할 만한 공식 사이트나 블로그 링크:**

*   **Original World Models Paper (David Ha and Jürgen Schmidhuber, 2018):** [https://worldmodels.github.io/](https://worldmodels.github.io/)
*   **Blog post summarizing the World Models paper:** [https://medium.com/@moelhaimer/world-models-simplified-de5a599529c2](https://medium.com/@moelhaimer/world-models-simplified-de5a599529c2)
*   **TensorFlow implementation of World Models:** [https://github.com/tensorlayer/tensorlayer/blob/master/examples/reinforcement_learning/world_model.py](https://github.com/tensorlayer/tensorlayer/blob/master/examples/reinforcement_learning/world_model.py)

**3. 간단한 코드 예시 (Python):**

다음은 World Models 아키텍처의 핵심 부분인 VAE를 사용하여 이미지를 압축하고 재구성하는 간단한 예시입니다.  전체 World Model 구현은 훨씬 복잡하며, 강화 학습 환경과의 통합이 필요합니다.

```python
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

# VAE 모델 정의
class VAE(tf.keras.Model):
    def __init__(self, latent_dim):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        self.encoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(28, 28, 1)),
            layers.Conv2D(32, kernel_size=3, strides=2, activation='relu'),
            layers.Conv2D(64, kernel_size=3, strides=2, activation='relu'),
            layers.Flatten(),
            layers.Dense(latent_dim * 2)  # 평균 및 분산
        ])
        self.decoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(latent_dim,)),
            layers.Dense(units=7*7*32, activation=tf.nn.relu),
            layers.Reshape(target_shape=(7, 7, 32)),
            layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu'),
            layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same', activation='relu'),
            layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding='same', activation='sigmoid')
        ])

    @tf.function
    def sample(self, eps=None):
        if eps is None:
            eps = tf.random.normal(shape=(100, self.latent_dim))
        return self.decode(eps, apply_sigmoid=True)

    def encode(self, x):
        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)
        return mean, logvar

    def reparameterize(self, mean, logvar):
        eps = tf.random.normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def decode(self, z, apply_sigmoid=False):
        logits = self.decoder(z)
        if apply_sigmoid:
            probs = tf.sigmoid(logits)
            return probs
        return logits


# MNIST 데이터 로드 및 전처리
(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

# 하이퍼파라미터 설정
latent_dim = 32
epochs = 10
batch_size = 64

# 모델 초기화
vae = VAE(latent_dim)

# 옵티마이저 설정
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

# 손실 함수 정의
def log_normal_pdf(sample, mean, logvar, raxis=1):
  log2pi = tf.math.log(2. * np.pi)
  return tf.reduce_sum(
      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),
      axis=raxis)


def compute_loss(model, x):
  mean, logvar = model.encode(x)
  z = model.reparameterize(mean, logvar)
  x_logit = model.decode(z)
  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)
  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])
  logpz = log_normal_pdf(z, 0., 0.)
  logqz_x = log_normal_pdf(z, mean, logvar)
  return -tf.reduce_mean(logpx_z + logpz - logqz_x)

@tf.function
def train_step(model, x, optimizer):
  with tf.GradientTape() as tape:
    loss = compute_loss(model, x)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

# 학습 루프
for epoch in range(1, epochs + 1):
    for batch in range(x_train.shape[0] // batch_size):
        x_batch = x_train[batch * batch_size : (batch + 1) * batch_size]
        train_step(vae, x_batch, optimizer)
    loss = compute_loss(vae, x_train)
    print(f'Epoch: {epoch}, Loss: {loss.numpy()}')

# 테스트 이미지 인코딩 및 디코딩
sample = x_test[0:1]
mean, logvar = vae.encode(sample)
z = vae.reparameterize(mean, logvar)
reconstructed_image = vae.decode(z, apply_sigmoid=True)

#결과 이미지 저장 (optional)
import matplotlib.pyplot as plt

plt.figure(figsize=(4, 4))
plt.imshow(sample[0], cmap='gray')
plt.title("Original Image")
plt.show()

plt.figure(figsize=(4, 4))
plt.imshow(reconstructed_image[0], cmap='gray')
plt.title("Reconstructed Image")
plt.show()

```

**4. 코드 실행 결과 예시:**

이 코드를 실행하면 MNIST 데이터셋을 사용하여 VAE를 학습합니다. 각 에폭마다 손실 값이 출력됩니다. 학습이 완료되면, 테스트 이미지 하나를 선택하여 인코딩 및 디코딩을 수행하고, 원본 이미지와 재구성된 이미지를 matplotlib을 사용하여 표시합니다.  재구성된 이미지는 원본 이미지와 유사하게 나타나야 합니다.  손실값과 이미지의 유사성은 에폭 횟수와 레이어 구성에 따라 달라집니다.

이 예시는 World Models의 한 부분인 VAE의 간단한 구현일 뿐이며, 실제 World Models는 더 복잡한 구조를 가지고 있음을 기억해야 합니다.  여기에는 RNN을 사용하여 환경의 역학을 모델링하고, 컨트롤러를 사용하여 행동을 계획하는 것이 포함됩니다.

